{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import numpy as np\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from processed database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set up data\n",
    "path = '/db/amazon_book_reviews_final.db'\n",
    "def import_data(db_path):\n",
    "    conn = sq.connect(db_path) #sqliteDB path goes in parantheses\n",
    "    crsr = conn.cursor()\n",
    "\n",
    "    df = pd.read_sql_query('''\n",
    "                SELECT *\n",
    "                FROM processed\n",
    "                ;\n",
    "                ''', conn)\n",
    "\n",
    "    df['star_rating'] = df['star_rating'].astype(float)\n",
    "    df['star_rating'] = df['star_rating'].astype(int) #convert rating to integer type\n",
    "    df['helpful_votes'] = df['helpful_votes'].astype(int) #convert rating to integer type  \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df = import_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YellowBrick Viz SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_dat = df[[\"star_rating\",\"helpful_votes\",\"product_title_length\",\"review_body_length\",\"cleaned_sentiment_star_rating\",\"difference\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank2D\n",
    "%matplotlib inline\n",
    "\n",
    "visualizer = Rank2D(algorithm=\"covariance\")\n",
    "visualizer.fit_transform(num_dat)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='star_rating', target='difference')\n",
    "visualizer.fit(df['star_rating'], df['difference'])\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='sentiment_star_rating', target='cleaned_sentiment_star_rating')\n",
    "visualizer.fit(X_dat['sentiment_star_rating'], X_dat['cleaned_sentiment_star_rating'])\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='sentiment_star_rating', target='star_rating')\n",
    "visualizer.fit(X_dat['sentiment_star_rating'], X_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(X_dat['sentiment_star_rating'], X_dat['star_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='cleaned_sentiment_star_rating', target='star_rating')\n",
    "visualizer.fit(X_dat['cleaned_sentiment_star_rating'], X_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(X_dat['cleaned_sentiment_star_rating'], X_dat['star_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='difference', target='star_rating')\n",
    "visualizer.fit(num_dat['difference'], num_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(num_dat['difference'], num_dat['star_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering  SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "visualizer = KElbowVisualizer(MiniBatchKMeans(), k=(4,12))\n",
    "\n",
    "visualizer.fit(df) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = MiniBatchKMeans(7)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X_dat) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling in Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df_pivot = df.pivot_table(index='customer_id',columns='product_title',values='star_rating',fill_value=0)\n",
    "X = df_pivot.T\n",
    "\n",
    "\n",
    "#parameters = {'n_components': [5, 10, 15, 20, 25, 30] }\n",
    "\n",
    "SVD = TruncatedSVD(n_components=10, random_state=15)\n",
    "SVD.fit(X)\n",
    "#search = GridSearchCV(SVD, parameters, scoring='roc_auc')\n",
    "#matrix = search.transform(X)\n",
    "matrix = SVD.fit_transform(X)\n",
    "corr = np.corrcoef(matrix)\n",
    "book_title = df_pivot.columns\n",
    "print(SVD.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_recs(book_title, corr, title):\n",
    "    book_list = book_title.tolist()\n",
    "    book_title = np.asarray(book_title)\n",
    "\n",
    "    book_idx = book_list.index(title)\n",
    "    corr_target = corr[book_idx]\n",
    "    corrs = np.concatenate((book_title,corr_target),axis=0)\n",
    "\n",
    "    top_5_idx = np.argsort(corr_target)[-6:-1]\n",
    "    top_5_values = [book_title[i] for i in top_5_idx]\n",
    "    print(top_5_values)\n",
    "\n",
    "\n",
    "print_recs(book_title, corr, \"The Stand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "df_pivot = df.pivot_table(index='customer_id',columns='product_title',values='star_rating',fill_value=0)\n",
    "X = df_pivot.T\n",
    "NMFmod = NMF(n_components=12)\n",
    "matrix = NMFmod.fit_transform(X)\n",
    "corr = np.corrcoef(matrix)\n",
    "book_title = df_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_recs(book_title, corr, title):\n",
    "    book_list = book_title.tolist()\n",
    "    book_title = np.asarray(book_title)\n",
    "\n",
    "    book_idx = book_list.index(title)\n",
    "    corr_target = corr[book_idx]\n",
    "    corrs = np.concatenate((book_title,corr_target),axis=0)\n",
    "\n",
    "    top_5_idx = np.argsort(corr_target)[-6:-1]\n",
    "    top_5_values = [book_title[i] for i in top_5_idx]\n",
    "    print(top_5_values)\n",
    "\n",
    "\n",
    "print_recs(book_title, corr, \"The Stand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling in LightFM\n",
    "Will allow for incorporation of product metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n",
    "    '''\n",
    "    Function to create an interaction matrix dataframe from transactional type interactions\n",
    "    Required Input -\n",
    "        - df = Pandas DataFrame containing user-item interactions\n",
    "        - user_col = column name containing user's identifier\n",
    "        - item_col = column name containing item's identifier\n",
    "        - rating col = column name containing user feedback on interaction with a given item\n",
    "        - norm (optional) = True if a normalization of ratings is needed\n",
    "        - threshold (required if norm = True) = value above which the rating is favorable\n",
    "    Expected output - \n",
    "        - Pandas dataframe with user-item interactions ready to be fed in a recommendation algorithm\n",
    "    '''\n",
    "    interactions = df.groupby([user_col, item_col])[rating_col] \\\n",
    "            .sum().unstack().reset_index(). \\\n",
    "            fillna(0).set_index(user_col)\n",
    "    if norm:\n",
    "        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n",
    "    return interactions\n",
    "\n",
    "\n",
    "def create_user_dict(interactions):\n",
    "    '''\n",
    "    Function to create a user dictionary based on their index and number in interaction dataset\n",
    "    Required Input - \n",
    "        interactions - dataset create by create_interaction_matrix\n",
    "    Expected Output -\n",
    "        user_dict - Dictionary type output containing interaction_index as key and user_id as value\n",
    "    '''\n",
    "    user_id = list(interactions.index)\n",
    "    user_dict = {}\n",
    "    counter = 0 \n",
    "    for i in user_id:\n",
    "        user_dict[i] = counter\n",
    "        counter += 1\n",
    "    return user_dict\n",
    "    \n",
    "def create_item_dict(df,id_col,name_col):\n",
    "    '''\n",
    "    Function to create an item dictionary based on their item_id and item name\n",
    "    Required Input - \n",
    "        - df = Pandas dataframe with Item information\n",
    "        - id_col = Column name containing unique identifier for an item\n",
    "        - name_col = Column name containing name of the item\n",
    "    Expected Output -\n",
    "        item_dict = Dictionary type output containing item_id as key and item_name as value\n",
    "    '''\n",
    "    item_dict ={}\n",
    "    for i in range(df.shape[0]):\n",
    "        item_dict[(df.loc[i,id_col])] = df.loc[i,name_col]\n",
    "    return item_dict\n",
    "\n",
    "\n",
    "def runMF(interactions, n_components=30, loss='warp', k=15, epoch=30,n_jobs = 4):\n",
    "    '''\n",
    "    Function to run matrix-factorization algorithm\n",
    "    Required Input -\n",
    "        - interactions = dataset create by create_interaction_matrix\n",
    "        - n_components = number of embeddings you want to create to define Item and user\n",
    "        - loss = loss function other options are logistic, brp\n",
    "        - epoch = number of epochs to run \n",
    "        - n_jobs = number of cores used for execution \n",
    "    Expected Output  -\n",
    "        Model - Trained model\n",
    "    '''\n",
    "    x = csr_matrix(interactions.values)\n",
    "    model = LightFM(no_components= n_components, loss=loss,k=k)\n",
    "    model.fit(x,epochs=epoch,num_threads = n_jobs)\n",
    "    return model\n",
    "\n",
    "def create_item_emdedding_distance_matrix(model,interactions):\n",
    "    '''\n",
    "    Function to create item-item distance embedding matrix\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "    Expected Output -\n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "    '''\n",
    "    df_item_norm_sparse = csr_matrix(model.item_embeddings)\n",
    "    similarities = cosine_similarity(df_item_norm_sparse)\n",
    "    print(similarities[0])\n",
    "\n",
    "    item_emdedding_distance_matrix = pd.DataFrame(similarities)\n",
    "    item_emdedding_distance_matrix.columns = interactions.columns\n",
    "    item_emdedding_distance_matrix.index = interactions.columns\n",
    "    return item_emdedding_distance_matrix\n",
    "\n",
    "def item_item_recommendation(item_emdedding_distance_matrix, item_id, \n",
    "                             item_dict, n_items = 10, show = True):\n",
    "    '''\n",
    "    Function to create item-item recommendation\n",
    "    Required Input - \n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "        - item_id  = item ID for which we need to generate recommended items\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - n_items = Number of items needed as an output\n",
    "    Expected Output -\n",
    "        - recommended_items = List of recommended items\n",
    "    '''\n",
    "    recommended_items = list(pd.Series(item_emdedding_distance_matrix.loc[item_id]. \\\n",
    "                                  sort_values(ascending = False).head(n_items+1). \\\n",
    "                                  index[1:n_items+1]))\n",
    "    if show == True:\n",
    "        print(\"Item of interest :{0}\".format(item_id))\n",
    "        print(\"Item similar to the above item:\")\n",
    "        counter = 1\n",
    "        for i in recommended_items:\n",
    "            print(str(counter) + '- ' +  i)\n",
    "            counter+=1\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>product_title</th>\n",
       "      <th>#GIRLBOSS</th>\n",
       "      <th>&amp;#34;I Know the Plans&amp;#34; Flexcover Journal</th>\n",
       "      <th>'Don't Make the Black Kids Angry': The hoax of black victimization and those who enable it.</th>\n",
       "      <th>'Salem's Lot</th>\n",
       "      <th>'Til the Well Runs Dry: A Novel</th>\n",
       "      <th>'White Girl Bleed A Lot': The Return of Racial Violence to America and How the Media Ignore It</th>\n",
       "      <th>002: Maus II: A Survivor's Tale: And Here My Troubles Began (Pantheon Graphic Novels)</th>\n",
       "      <th>1,000 Gluten-Free Recipes (1,000 Recipes)</th>\n",
       "      <th>1,000 Places to See Before You Die: Revised Second Edition</th>\n",
       "      <th>1,000 Unforgettable Senior Moments: Of Which We Could Remember Only 246</th>\n",
       "      <th>...</th>\n",
       "      <th>iPhone 5 For Dummies</th>\n",
       "      <th>iPhone For Seniors For Dummies</th>\n",
       "      <th>iPhone: The Missing Manual</th>\n",
       "      <th>iPhone: The Missing Manual (Missing Manuals)</th>\n",
       "      <th>knit, Swirl! Uniquely Flattering, One Piece, One Seam Swirl Jackets; Foreword by Cat Bordhi</th>\n",
       "      <th>salt.</th>\n",
       "      <th>the Next EXIT (2013) (Next Exit: The Most Complete Interstate Highway Guide Ever Printed)</th>\n",
       "      <th>unPHILtered: The Way I See It</th>\n",
       "      <th>xkcd: volume 0</th>\n",
       "      <th>¿Eres Mi Mama? (Bright &amp; Early Board Books(TM)) (Spanish Edition)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168364</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "product_title  #GIRLBOSS  &#34;I Know the Plans&#34; Flexcover Journal  \\\n",
       "customer_id                                                              \n",
       "96533                0.0                                           0.0   \n",
       "168364               0.0                                           0.0   \n",
       "329880               0.0                                           0.0   \n",
       "396880               0.0                                           0.0   \n",
       "405716               0.0                                           0.0   \n",
       "\n",
       "product_title  'Don't Make the Black Kids Angry': The hoax of black victimization and those who enable it.  \\\n",
       "customer_id                                                                                                  \n",
       "96533                                                        0.0                                             \n",
       "168364                                                       0.0                                             \n",
       "329880                                                       0.0                                             \n",
       "396880                                                       0.0                                             \n",
       "405716                                                       0.0                                             \n",
       "\n",
       "product_title  'Salem's Lot  'Til the Well Runs Dry: A Novel  \\\n",
       "customer_id                                                    \n",
       "96533                   0.0                              0.0   \n",
       "168364                  0.0                              0.0   \n",
       "329880                  0.0                              0.0   \n",
       "396880                  0.0                              0.0   \n",
       "405716                  0.0                              0.0   \n",
       "\n",
       "product_title  'White Girl Bleed A Lot': The Return of Racial Violence to America and How the Media Ignore It  \\\n",
       "customer_id                                                                                                     \n",
       "96533                                                        0.0                                                \n",
       "168364                                                       0.0                                                \n",
       "329880                                                       0.0                                                \n",
       "396880                                                       0.0                                                \n",
       "405716                                                       0.0                                                \n",
       "\n",
       "product_title  002: Maus II: A Survivor's Tale: And Here My Troubles Began (Pantheon Graphic Novels)  \\\n",
       "customer_id                                                                                            \n",
       "96533                                                        0.0                                       \n",
       "168364                                                       0.0                                       \n",
       "329880                                                       0.0                                       \n",
       "396880                                                       0.0                                       \n",
       "405716                                                       0.0                                       \n",
       "\n",
       "product_title  1,000 Gluten-Free Recipes (1,000 Recipes)  \\\n",
       "customer_id                                                \n",
       "96533                                                0.0   \n",
       "168364                                               0.0   \n",
       "329880                                               0.0   \n",
       "396880                                               0.0   \n",
       "405716                                               0.0   \n",
       "\n",
       "product_title  1,000 Places to See Before You Die: Revised Second Edition  \\\n",
       "customer_id                                                                 \n",
       "96533                                                        0.0            \n",
       "168364                                                       0.0            \n",
       "329880                                                       0.0            \n",
       "396880                                                       0.0            \n",
       "405716                                                       0.0            \n",
       "\n",
       "product_title  1,000 Unforgettable Senior Moments: Of Which We Could Remember Only 246  \\\n",
       "customer_id                                                                              \n",
       "96533                                                        0.0                         \n",
       "168364                                                       0.0                         \n",
       "329880                                                       0.0                         \n",
       "396880                                                       0.0                         \n",
       "405716                                                       0.0                         \n",
       "\n",
       "product_title                                ...                                  \\\n",
       "customer_id                                  ...                                   \n",
       "96533                                        ...                                   \n",
       "168364                                       ...                                   \n",
       "329880                                       ...                                   \n",
       "396880                                       ...                                   \n",
       "405716                                       ...                                   \n",
       "\n",
       "product_title  iPhone 5 For Dummies  iPhone For Seniors For Dummies  \\\n",
       "customer_id                                                           \n",
       "96533                           0.0                             0.0   \n",
       "168364                          0.0                             0.0   \n",
       "329880                          0.0                             0.0   \n",
       "396880                          0.0                             0.0   \n",
       "405716                          0.0                             0.0   \n",
       "\n",
       "product_title  iPhone: The Missing Manual  \\\n",
       "customer_id                                 \n",
       "96533                                 0.0   \n",
       "168364                                0.0   \n",
       "329880                                0.0   \n",
       "396880                                0.0   \n",
       "405716                                0.0   \n",
       "\n",
       "product_title  iPhone: The Missing Manual (Missing Manuals)  \\\n",
       "customer_id                                                   \n",
       "96533                                                   0.0   \n",
       "168364                                                  0.0   \n",
       "329880                                                  0.0   \n",
       "396880                                                  0.0   \n",
       "405716                                                  0.0   \n",
       "\n",
       "product_title  knit, Swirl! Uniquely Flattering, One Piece, One Seam Swirl Jackets; Foreword by Cat Bordhi  \\\n",
       "customer_id                                                                                                  \n",
       "96533                                                        0.0                                             \n",
       "168364                                                       0.0                                             \n",
       "329880                                                       0.0                                             \n",
       "396880                                                       0.0                                             \n",
       "405716                                                       0.0                                             \n",
       "\n",
       "product_title  salt.  \\\n",
       "customer_id            \n",
       "96533            0.0   \n",
       "168364           0.0   \n",
       "329880           0.0   \n",
       "396880           0.0   \n",
       "405716           0.0   \n",
       "\n",
       "product_title  the Next EXIT (2013) (Next Exit: The Most Complete Interstate Highway Guide Ever Printed)  \\\n",
       "customer_id                                                                                                \n",
       "96533                                                        0.0                                           \n",
       "168364                                                       0.0                                           \n",
       "329880                                                       0.0                                           \n",
       "396880                                                       0.0                                           \n",
       "405716                                                       0.0                                           \n",
       "\n",
       "product_title  unPHILtered: The Way I See It  xkcd: volume 0  \\\n",
       "customer_id                                                    \n",
       "96533                                    0.0             0.0   \n",
       "168364                                   0.0             0.0   \n",
       "329880                                   0.0             0.0   \n",
       "396880                                   0.0             0.0   \n",
       "405716                                   0.0             0.0   \n",
       "\n",
       "product_title  ¿Eres Mi Mama? (Bright & Early Board Books(TM)) (Spanish Edition)  \n",
       "customer_id                                                                       \n",
       "96533                                                        0.0                  \n",
       "168364                                                       0.0                  \n",
       "329880                                                       0.0                  \n",
       "396880                                                       0.0                  \n",
       "405716                                                       0.0                  \n",
       "\n",
       "[5 rows x 8916 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating interaction matrix using rating data\n",
    "interactions = create_interaction_matrix(df = df,\n",
    "                                         user_col = 'customer_id',\n",
    "                                         item_col = 'product_title',\n",
    "                                         rating_col = 'star_rating')\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create User Dict\n",
    "user_dict = create_user_dict(interactions=interactions)\n",
    "# Create Item dict\n",
    "movies_dict = create_item_dict(df = df,\n",
    "                               id_col = 'product_id',\n",
    "                               name_col = 'product_title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from lightfm import LightFM\n",
    "mf_model = runMF(interactions = interactions,\n",
    "                 n_components = 30,\n",
    "                 loss = 'warp',\n",
    "                 epoch = 30,\n",
    "                 n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000012 -0.2752789   0.33693877 ...,  0.08869521 -0.17049016\n",
      " -0.07174084]\n"
     ]
    }
   ],
   "source": [
    "## Creating item-item distance matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "item_item_dist = create_item_emdedding_distance_matrix(model = mf_model,\n",
    "                                                       interactions = interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _pickle as p\n",
    "outfile = \"/db/lightfm_item_matrix2.p\"\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    p.dump(item_item_dist, pickle_file)\n",
    "    \n",
    "    \n",
    "outfile2 = \"/db/lightfm_movie_dict.p\"\n",
    "with open(outfile2, 'wb') as pickle2:  \n",
    "    p.dump(movies_dict, pickle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calling 10 recommended items for item id \n",
    "rec_list = item_item_recommendation(item_emdedding_distance_matrix = item_item_dist,\n",
    "                                    item_id = 'The Stand',\n",
    "                                    item_dict = movies_dict,\n",
    "                                    n_items = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling in Suprise  Works best for User-Item and no metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_dict = {'itemID': list(df.product_title),\n",
    "                'userID': list(df.customer_id),\n",
    "                'rating': list(df.star_rating)}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "\n",
    "\n",
    "def get_top_k(predictions, k):\n",
    "    '''Return a top_k dicts where keys are user ids and values are lists of\n",
    "    tuples [(item id, rating estimation) ...].\n",
    "\n",
    "    Takes in a list of predictions as returned by the test method.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_k = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=lambda x:x[1], reverse=True)\n",
    "        top_k[uid] = user_ratings[:k]\n",
    "\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are here testing on the WHOLE dataset. Which means that all the ratings we\n",
    "# are predicting are already known, but it does not really matter.\n",
    "testset = data.construct_testset(raw_testset=data.raw_ratings)\n",
    "predictions = algo.test(testset)\n",
    "#accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k = get_top_k(predictions, 5)\n",
    "\n",
    "# Print the recommended items\n",
    "for uid, user_ratings in top_k.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "\n",
    "\n",
    "\n",
    "# Compute the total number of recommended items.\n",
    "all_recommended_items = set(iid for (_, user_ratings) in top_k.items() for\n",
    "                            (iid, _) in user_ratings)\n",
    "\n",
    "print('Number of recommended items:', len(all_recommended_items), 'over',\n",
    "      len(top_k), 'users')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
