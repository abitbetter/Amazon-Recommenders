{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up data\n",
    "path = '/Users/Dustin/GT_project/wrangled_reviews.db'\n",
    "def import_data(db_path):\n",
    "    conn = sq.connect(db_path) #sqliteDB path goes in parantheses\n",
    "    crsr = conn.cursor()\n",
    "\n",
    "    df = pd.read_sql_query('''\n",
    "                SELECT *\n",
    "                FROM trunc_books\n",
    "                ;\n",
    "                ''', conn)\n",
    "\n",
    "    df['star_rating'] = df['star_rating'].astype(float)\n",
    "    df['star_rating'] = df['star_rating'].astype(int) #convert rating to integer type\n",
    "    df['helpful_votes'] = df['helpful_votes'].astype(int) #convert rating to integer type\n",
    "\n",
    "    df['review_body'] = df['review_body'].astype(str) #convert to str\n",
    "    df['review_headline'] = df['review_headline'].astype(str) #convert to str\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "df = import_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "#len(df)\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "   words = data.split(\" \")\n",
    "   num_words = len(words)\n",
    "   return num_words\n",
    "\n",
    "df['review_word_count']=0\n",
    "df['review_hl_count']=0\n",
    "\n",
    "df['review_word_count'] = df['review_body'].map(count_words)\n",
    "df['review_hl_count'] = df['review_headline'].map(count_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat = df[['product_parent','star_rating','helpful_votes','review_word_count','review_hl_count']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank2D\n",
    "\n",
    "visualizer = Rank2D(algorithm=\"pearson\")\n",
    "visualizer.fit_transform(X_dat)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='review_word_count', target='helpful_votes')\n",
    "visualizer.fit(X_dat['review_word_count'], X_dat['helpful_votes'])\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "visualizer = KElbowVisualizer(MiniBatchKMeans(), k=(4,12))\n",
    "\n",
    "visualizer.fit(X_dat) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = MiniBatchKMeans(12)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X_dat) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_dict = {'itemID': list(df.product_id),\n",
    "                'userID': list(df.customer_id),\n",
    "                'rating': list(df.star_rating)}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Using Suprise package\n",
    "# Split data into 5 folds\n",
    "\n",
    "data.split(n_folds=5)\n",
    "\n",
    "from surprise import SVD, evaluate\n",
    "from surprise import NMF, model_selection\n",
    "\n",
    "# svd\n",
    "algo = SVD()\n",
    "model_selection.cross_validate(algo, data, measures=['RMSE'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf\n",
    "algo = NMF()\n",
    "nmf_mod = model_selection.cross_validate(algo, data, measures=['RMSE'])\n",
    "nmf_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(predictions, userID, movies, original_ratings, num_recommendations):\n",
    "    \n",
    "    # Get and sort the user's predictions\n",
    "    user_row_number = userID - 1 # User ID starts at 1, not 0\n",
    "    sorted_user_predictions = preds.iloc[user_row_number].sort_values(ascending=False) # User ID starts at 1\n",
    "    \n",
    "    # Get the user's data and merge in the movie information.\n",
    "    user_data = original_ratings[original_ratings.user_id == (userID)]\n",
    "    user_full = (user_data.merge(movies, how = 'left', left_on = 'movie_id', right_on = 'movie_id').\n",
    "                     sort_values(['rating'], ascending=False)\n",
    "                 )\n",
    "    \n",
    "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "    recommendations = (movies[~movies['movie_id'].isin(user_full['movie_id'])].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "               left_on = 'movie_id',\n",
    "               right_on = 'movie_id').\n",
    "         rename(columns = {user_row_number: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).\n",
    "                       iloc[:num_recommendations, :-1]\n",
    "                      )\n",
    "\n",
    "    return user_full, recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
