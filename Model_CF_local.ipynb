{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import numpy as np\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from processed database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set up data\n",
    "path = '/db/wrangled_reviews.db'\n",
    "def import_data(db_path):\n",
    "    conn = sq.connect(db_path) #sqliteDB path goes in parantheses\n",
    "    crsr = conn.cursor()\n",
    "\n",
    "    df = pd.read_sql_query('''\n",
    "                SELECT customer_id, product_id, product_title, product_parent, star_rating, helpful_votes, \n",
    "                review_word_count, review_hl_count, cleaned_sentiment_star_rating, difference\n",
    "                FROM processed\n",
    "                ;\n",
    "                ''', conn)\n",
    "\n",
    "    df['star_rating'] = df['star_rating'].astype(float)\n",
    "    df['star_rating'] = df['star_rating'].astype(int) #convert rating to integer type\n",
    "    df['helpful_votes'] = df['helpful_votes'].astype(int) #convert rating to integer type  \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df = import_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_word_count</th>\n",
       "      <th>review_hl_count</th>\n",
       "      <th>cleaned_sentiment_star_rating</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40676812</td>\n",
       "      <td>1938067126</td>\n",
       "      <td>Crimes of the Educators: How Utopians Are Usin...</td>\n",
       "      <td>402004849</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2784618</td>\n",
       "      <td>014017737X</td>\n",
       "      <td>The Pearl</td>\n",
       "      <td>779170984</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2876528</td>\n",
       "      <td>0982207743</td>\n",
       "      <td>Primal Blueprint Quick and Easy Meals: Delicio...</td>\n",
       "      <td>225126623</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33678379</td>\n",
       "      <td>080072433X</td>\n",
       "      <td>Trial Run (Fault Lines)</td>\n",
       "      <td>42136245</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>4</td>\n",
       "      <td>3.009420</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32159651</td>\n",
       "      <td>0615815650</td>\n",
       "      <td>Methods of Persuasion: How to Use Psychology t...</td>\n",
       "      <td>625464646</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id                                      product_title  \\\n",
       "0     40676812  1938067126  Crimes of the Educators: How Utopians Are Usin...   \n",
       "1      2784618  014017737X                                          The Pearl   \n",
       "2      2876528  0982207743  Primal Blueprint Quick and Easy Meals: Delicio...   \n",
       "3     33678379  080072433X                            Trial Run (Fault Lines)   \n",
       "4     32159651  0615815650  Methods of Persuasion: How to Use Psychology t...   \n",
       "\n",
       "   product_parent  star_rating  helpful_votes  review_word_count  \\\n",
       "0       402004849            5              0                  1   \n",
       "1       779170984            5              0                  8   \n",
       "2       225126623            3              1                 10   \n",
       "3        42136245            3              0                277   \n",
       "4       625464646            3              1                 22   \n",
       "\n",
       "   review_hl_count  cleaned_sentiment_star_rating  difference  \n",
       "0                2                       5.000000    0.000000  \n",
       "1                2                       3.000000    2.000000  \n",
       "2                2                       2.000000    1.000000  \n",
       "3                4                       3.009420    0.009420  \n",
       "4                4                       2.636364    0.363636  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YellowBrick Viz SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import Rank2D\n",
    "%matplotlib inline\n",
    "\n",
    "visualizer = Rank2D(algorithm=\"pearson\")\n",
    "visualizer.fit_transform(df)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='star_rating', target='difference')\n",
    "visualizer.fit(df['star_rating'], df['difference'])\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='sentiment_star_rating', target='cleaned_sentiment_star_rating')\n",
    "visualizer.fit(X_dat['sentiment_star_rating'], X_dat['cleaned_sentiment_star_rating'])\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='sentiment_star_rating', target='star_rating')\n",
    "visualizer.fit(X_dat['sentiment_star_rating'], X_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(X_dat['sentiment_star_rating'], X_dat['star_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='cleaned_sentiment_star_rating', target='star_rating')\n",
    "visualizer.fit(X_dat['cleaned_sentiment_star_rating'], X_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(X_dat['cleaned_sentiment_star_rating'], X_dat['star_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "visualizer = JointPlotVisualizer(feature='difference', target='star_rating')\n",
    "visualizer.fit(X_dat['difference'], X_dat['star_rating'])\n",
    "visualizer.poof()\n",
    "\n",
    "np.corrcoef(X_dat['difference'], X_dat['star_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering  SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "visualizer = KElbowVisualizer(MiniBatchKMeans(), k=(4,12))\n",
    "\n",
    "visualizer.fit(X_dat) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = MiniBatchKMeans(7)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X_dat) # Fit the training data to the visualizer\n",
    "visualizer.poof() # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling in Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "df_pivot = df.pivot_table(index='customer_id',columns='product_title',values='star_rating',fill_value=0)\n",
    "X = df_pivot.T\n",
    "SVD = TruncatedSVD(n_components=12, random_state=17)\n",
    "matrix = SVD.fit_transform(X)\n",
    "corr = np.corrcoef(matrix)\n",
    "book_title = df_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump((corr,book_title), 'svd_mod2.joblib', compress=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_recs(book_title, corr, title):\n",
    "    book_list = book_title.tolist()\n",
    "    book_title = np.asarray(book_title)\n",
    "\n",
    "    book_idx = book_list.index(title)\n",
    "    corr_target = corr[book_idx]\n",
    "    corrs = np.concatenate((book_title,corr_target),axis=0)\n",
    "\n",
    "    top_5_idx = np.argsort(corr_target)[-6:-1]\n",
    "    top_5_values = [book_title[i] for i in top_5_idx]\n",
    "    print(top_5_values)\n",
    "\n",
    "\n",
    "print_recs(book_title, corr, \"The Stand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "df_pivot = df.pivot_table(index='customer_id',columns='product_title',values='star_rating',fill_value=0)\n",
    "X = df_pivot.T\n",
    "NMFmod = NMF(n_components=12)\n",
    "matrix = NMFmod.fit_transform(X)\n",
    "corr = np.corrcoef(matrix)\n",
    "book_title = df_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_recs(book_title, corr, title):\n",
    "    book_list = book_title.tolist()\n",
    "    book_title = np.asarray(book_title)\n",
    "\n",
    "    book_idx = book_list.index(title)\n",
    "    corr_target = corr[book_idx]\n",
    "    corrs = np.concatenate((book_title,corr_target),axis=0)\n",
    "\n",
    "    top_5_idx = np.argsort(corr_target)[-6:-1]\n",
    "    top_5_values = [book_title[i] for i in top_5_idx]\n",
    "    print(top_5_values)\n",
    "\n",
    "\n",
    "print_recs(book_title, corr, \"The Stand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling in LightFM\n",
    "Will allow for incorporation of product metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n",
    "    '''\n",
    "    Function to create an interaction matrix dataframe from transactional type interactions\n",
    "    Required Input -\n",
    "        - df = Pandas DataFrame containing user-item interactions\n",
    "        - user_col = column name containing user's identifier\n",
    "        - item_col = column name containing item's identifier\n",
    "        - rating col = column name containing user feedback on interaction with a given item\n",
    "        - norm (optional) = True if a normalization of ratings is needed\n",
    "        - threshold (required if norm = True) = value above which the rating is favorable\n",
    "    Expected output - \n",
    "        - Pandas dataframe with user-item interactions ready to be fed in a recommendation algorithm\n",
    "    '''\n",
    "    interactions = df.groupby([user_col, item_col])[rating_col] \\\n",
    "            .sum().unstack().reset_index(). \\\n",
    "            fillna(0).set_index(user_col)\n",
    "    if norm:\n",
    "        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n",
    "    return interactions\n",
    "\n",
    "\n",
    "def create_user_dict(interactions):\n",
    "    '''\n",
    "    Function to create a user dictionary based on their index and number in interaction dataset\n",
    "    Required Input - \n",
    "        interactions - dataset create by create_interaction_matrix\n",
    "    Expected Output -\n",
    "        user_dict - Dictionary type output containing interaction_index as key and user_id as value\n",
    "    '''\n",
    "    user_id = list(interactions.index)\n",
    "    user_dict = {}\n",
    "    counter = 0 \n",
    "    for i in user_id:\n",
    "        user_dict[i] = counter\n",
    "        counter += 1\n",
    "    return user_dict\n",
    "    \n",
    "def create_item_dict(df,id_col,name_col):\n",
    "    '''\n",
    "    Function to create an item dictionary based on their item_id and item name\n",
    "    Required Input - \n",
    "        - df = Pandas dataframe with Item information\n",
    "        - id_col = Column name containing unique identifier for an item\n",
    "        - name_col = Column name containing name of the item\n",
    "    Expected Output -\n",
    "        item_dict = Dictionary type output containing item_id as key and item_name as value\n",
    "    '''\n",
    "    item_dict ={}\n",
    "    for i in range(df.shape[0]):\n",
    "        item_dict[(df.loc[i,id_col])] = df.loc[i,name_col]\n",
    "    return item_dict\n",
    "\n",
    "\n",
    "def runMF(interactions, n_components=30, loss='warp', k=15, epoch=30,n_jobs = 4):\n",
    "    '''\n",
    "    Function to run matrix-factorization algorithm\n",
    "    Required Input -\n",
    "        - interactions = dataset create by create_interaction_matrix\n",
    "        - n_components = number of embeddings you want to create to define Item and user\n",
    "        - loss = loss function other options are logistic, brp\n",
    "        - epoch = number of epochs to run \n",
    "        - n_jobs = number of cores used for execution \n",
    "    Expected Output  -\n",
    "        Model - Trained model\n",
    "    '''\n",
    "    x = csr_matrix(interactions.values)\n",
    "    model = LightFM(no_components= n_components, loss=loss,k=k)\n",
    "    model.fit(x,epochs=epoch,num_threads = n_jobs)\n",
    "    return model\n",
    "\n",
    "def create_item_emdedding_distance_matrix(model,interactions):\n",
    "    '''\n",
    "    Function to create item-item distance embedding matrix\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "    Expected Output -\n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "    '''\n",
    "    df_item_norm_sparse = csr_matrix(model.item_embeddings)\n",
    "    similarities = cosine_similarity(df_item_norm_sparse)\n",
    "    item_emdedding_distance_matrix = pd.DataFrame(similarities)\n",
    "    item_emdedding_distance_matrix.columns = interactions.columns\n",
    "    item_emdedding_distance_matrix.index = interactions.columns\n",
    "    return item_emdedding_distance_matrix\n",
    "\n",
    "def item_item_recommendation(item_emdedding_distance_matrix, item_id, \n",
    "                             item_dict, n_items = 10, show = True):\n",
    "    '''\n",
    "    Function to create item-item recommendation\n",
    "    Required Input - \n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "        - item_id  = item ID for which we need to generate recommended items\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - n_items = Number of items needed as an output\n",
    "    Expected Output -\n",
    "        - recommended_items = List of recommended items\n",
    "    '''\n",
    "    recommended_items = list(pd.Series(item_emdedding_distance_matrix.loc[item_id,:]. \\\n",
    "                                  sort_values(ascending = False).head(n_items+1). \\\n",
    "                                  index[1:n_items+1]))\n",
    "    if show == True:\n",
    "        print(\"Item of interest :{0}\".format(item_dict[item_id]))\n",
    "        print(\"Item similar to the above item:\")\n",
    "        counter = 1\n",
    "        for i in recommended_items:\n",
    "            print(str(counter) + '- ' +  item_dict[i])\n",
    "            counter+=1\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>product_id</th>\n",
       "      <th>0002250519</th>\n",
       "      <th>000713326X</th>\n",
       "      <th>0007149832</th>\n",
       "      <th>0007162219</th>\n",
       "      <th>0007236360</th>\n",
       "      <th>0007256817</th>\n",
       "      <th>0007320817</th>\n",
       "      <th>0007398557</th>\n",
       "      <th>0007446977</th>\n",
       "      <th>0007447868</th>\n",
       "      <th>...</th>\n",
       "      <th>B00EC8YBD8</th>\n",
       "      <th>B00ERNP2JU</th>\n",
       "      <th>B00ES27PRM</th>\n",
       "      <th>B00FY2QHU6</th>\n",
       "      <th>B00IID8Z12</th>\n",
       "      <th>B00JKSTQE4</th>\n",
       "      <th>B00MNM6EKI</th>\n",
       "      <th>B00MPREWL4</th>\n",
       "      <th>B00N4FLH82</th>\n",
       "      <th>B00QQ1RFEG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421085</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30854 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "product_id   0002250519  000713326X  0007149832  0007162219  0007236360  \\\n",
       "customer_id                                                               \n",
       "96533               0.0         0.0         0.0         0.0         0.0   \n",
       "421085              0.0         0.0         0.0         0.0         0.0   \n",
       "543134              0.0         0.0         0.0         0.0         0.0   \n",
       "565775              0.0         0.0         0.0         0.0         0.0   \n",
       "705489              0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "product_id   0007256817  0007320817  0007398557  0007446977  0007447868  \\\n",
       "customer_id                                                               \n",
       "96533               0.0         0.0         0.0         0.0         0.0   \n",
       "421085              0.0         0.0         0.0         0.0         0.0   \n",
       "543134              0.0         0.0         0.0         0.0         0.0   \n",
       "565775              0.0         0.0         0.0         0.0         0.0   \n",
       "705489              0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "product_id      ...      B00EC8YBD8  B00ERNP2JU  B00ES27PRM  B00FY2QHU6  \\\n",
       "customer_id     ...                                                       \n",
       "96533           ...             0.0         0.0         0.0         0.0   \n",
       "421085          ...             0.0         0.0         0.0         0.0   \n",
       "543134          ...             0.0         0.0         0.0         0.0   \n",
       "565775          ...             0.0         0.0         0.0         0.0   \n",
       "705489          ...             0.0         0.0         0.0         0.0   \n",
       "\n",
       "product_id   B00IID8Z12  B00JKSTQE4  B00MNM6EKI  B00MPREWL4  B00N4FLH82  \\\n",
       "customer_id                                                               \n",
       "96533               0.0         0.0         0.0         0.0         0.0   \n",
       "421085              0.0         0.0         0.0         0.0         0.0   \n",
       "543134              0.0         0.0         0.0         0.0         0.0   \n",
       "565775              0.0         0.0         0.0         0.0         0.0   \n",
       "705489              0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "product_id   B00QQ1RFEG  \n",
       "customer_id              \n",
       "96533               0.0  \n",
       "421085              0.0  \n",
       "543134              0.0  \n",
       "565775              0.0  \n",
       "705489              0.0  \n",
       "\n",
       "[5 rows x 30854 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating interaction matrix using rating data\n",
    "interactions = create_interaction_matrix(df = df,\n",
    "                                         user_col = 'customer_id',\n",
    "                                         item_col = 'product_id',\n",
    "                                         rating_col = 'star_rating')\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create User Dict\n",
    "user_dict = create_user_dict(interactions=interactions)\n",
    "# Create Item dict\n",
    "movies_dict = create_item_dict(df = df,\n",
    "                               id_col = 'product_id',\n",
    "                               name_col = 'product_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from lightfm import LightFM\n",
    "mf_model = runMF(interactions = interactions,\n",
    "                 n_components = 30,\n",
    "                 loss = 'warp',\n",
    "                 epoch = 30,\n",
    "                 n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b95f1b173683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m item_item_dist = create_item_emdedding_distance_matrix(model = mf_model,\n\u001b[0;32m----> 4\u001b[0;31m                                                        interactions = interactions)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9573fa9b2ee9>\u001b[0m in \u001b[0;36mcreate_item_emdedding_distance_matrix\u001b[0;34m(model, interactions)\u001b[0m\n\u001b[1;32m     77\u001b[0m     '''\n\u001b[1;32m     78\u001b[0m     \u001b[0mdf_item_norm_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_item_norm_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mitem_emdedding_distance_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mitem_emdedding_distance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Creating item-item distance matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "item_item_dist = create_item_emdedding_distance_matrix(model = mf_model,\n",
    "                                                       interactions = interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calling 10 recommended items for item id \n",
    "rec_list = item_item_recommendation(item_emdedding_distance_matrix = item_item_dist,\n",
    "                                    item_id = 5378,\n",
    "                                    item_dict = movies_dict,\n",
    "                                    n_items = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling in Suprise  Works best for User-Item and no metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# to load dataset from pandas df, we need `load_fromm_df` method in surprise lib\n",
    "\n",
    "ratings_dict = {'itemID': list(df.product_title),\n",
    "                'userID': list(df.customer_id),\n",
    "                'rating': list(df.star_rating)}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "from collections import defaultdict\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "\n",
    "\n",
    "def get_top_k(predictions, k):\n",
    "    '''Return a top_k dicts where keys are user ids and values are lists of\n",
    "    tuples [(item id, rating estimation) ...].\n",
    "\n",
    "    Takes in a list of predictions as returned by the test method.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_k = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=lambda x:x[1], reverse=True)\n",
    "        top_k[uid] = user_ratings[:k]\n",
    "\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are here testing on the WHOLE dataset. Which means that all the ratings we\n",
    "# are predicting are already known, but it does not really matter.\n",
    "testset = data.construct_testset(raw_testset=data.raw_ratings)\n",
    "predictions = algo.test(testset)\n",
    "#accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k = get_top_k(predictions, 5)\n",
    "\n",
    "# Print the recommended items\n",
    "for uid, user_ratings in top_k.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "\n",
    "\n",
    "\n",
    "# Compute the total number of recommended items.\n",
    "all_recommended_items = set(iid for (_, user_ratings) in top_k.items() for\n",
    "                            (iid, _) in user_ratings)\n",
    "\n",
    "print('Number of recommended items:', len(all_recommended_items), 'over',\n",
    "      len(top_k), 'users')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
